# record_student_play.py
import argparse
import os
import gymnasium as gym
import torch
import numpy as np
from collections import deque
from gymnasium.wrappers import RecordVideo
import torchvision.transforms as T
import torch.nn.functional as F
import torch.nn as nn

# ------------------------------
# CarRacingDiscrete (í›ˆë ¨ ë•Œì™€ ë™ì¼)
# ------------------------------
class CarRacingDiscrete(gym.Wrapper):
    ACTIONS = [
        np.array([-1.0, 0.0, 0.0], dtype=np.float32),  # ì¢ŒíšŒì „
        np.array([1.0, 0.0, 0.0], dtype=np.float32),   # ìš°íšŒì „
        np.array([0.0, 1.0, 0.0], dtype=np.float32),   # ê°€ì†
        np.array([0.0, 0.0, 0.8], dtype=np.float32),   # ë¸Œë ˆì´í¬
        np.array([-1.0, 1.0, 0.0], dtype=np.float32),  # ì¢ŒíšŒì „ + ê°€ì†
        np.array([1.0, 1.0, 0.0], dtype=np.float32),   # ìš°íšŒì „ + ê°€ì†
        np.array([0.0, 0.0, 0.0], dtype=np.float32),   # ì•„ë¬´ê²ƒë„ ì•ˆí•¨
    ]
    
    def __init__(self, resize=(84, 84)):
        env = gym.make("CarRacing-v3", render_mode="rgb_array")
        super().__init__(env)
        self.action_space = gym.spaces.Discrete(len(self.ACTIONS))
        self.observation_space = gym.spaces.Box(0, 255, (resize[0], resize[1], 1), dtype=np.uint8)
        self.transform = T.Compose([
            T.ToPILImage(),
            T.Grayscale(num_output_channels=1),
            T.Resize(resize, interpolation=T.InterpolationMode.BILINEAR),
            T.ToTensor(),
        ])
    
    def step(self, action):
        continuous_action = CarRacingDiscrete.ACTIONS[action]
        obs, reward, terminated, truncated, info = self.env.step(continuous_action)
        frame = self.transform(obs).squeeze(0)
        return (frame * 255).byte().numpy(), reward, terminated, truncated, info
    
    def reset(self, **kwargs):
        obs, info = self.env.reset(**kwargs)
        frame = self.transform(obs).squeeze(0)
        return (frame * 255).byte().numpy(), info

# ------------------------------
# DQN ë„¤íŠ¸ì›Œí¬ (í›ˆë ¨ ë•Œì™€ ë™ì¼)
# ------------------------------
class DQN(nn.Module):
    def __init__(self, h, w, outputs):
        super().__init__()
        self.conv1 = nn.Conv2d(4, 32, 8, 4)
        self.conv2 = nn.Conv2d(32, 64, 4, 2)
        self.conv3 = nn.Conv2d(64, 64, 3, 1)
        
        def conv2d_size_out(size, kernel_size, stride):
            return (size - (kernel_size - 1) - 1) // stride + 1
        
        convw = conv2d_size_out(conv2d_size_out(conv2d_size_out(w, 8, 4), 4, 2), 3, 1)
        convh = conv2d_size_out(conv2d_size_out(conv2d_size_out(h, 8, 4), 4, 2), 3, 1)
        linear_input_size = convw * convh * 64
        
        self.fc = nn.Linear(linear_input_size, 512)
        self.head = nn.Linear(512, outputs)
    
    def forward(self, x):
        x = x / 255.0
        x = F.relu(self.conv1(x))
        x = F.relu(self.conv2(x))
        x = F.relu(self.conv3(x))
        x = torch.flatten(x, 1)
        x = F.relu(self.fc(x))
        return self.head(x)

# ------------------------------
# FrameStack (í›ˆë ¨ ë•Œì™€ ë™ì¼)
# ------------------------------
class FrameStack:
    def __init__(self, k):
        self.k = k
        self.frames = deque([], maxlen=k)
    
    def reset(self, obs):
        for _ in range(self.k):
            self.frames.append(obs)
        return np.stack(self.frames, axis=0)
    
    def step(self, obs):
        self.frames.append(obs)
        return np.stack(self.frames, axis=0)

# ------------------------------
# ë©”ì¸ ìŠ¤í¬ë¦½íŠ¸
# ------------------------------
if __name__ == '__main__':
    parser = argparse.ArgumentParser(description='Record student DQN model playing CarRacing')
    parser.add_argument('-w', '--weights', required=True, 
                       help='Path to student model weights (.pt file)')
    parser.add_argument('-e', '--episodes', type=int, default=3,
                       help='Number of episodes to record (default: 3)')
    parser.add_argument('--seed', type=int, default=42,
                       help='Random seed for reproducible results (default: 42)')
    parser.add_argument('--max-steps', type=int, default=1000,
                       help='Maximum steps per episode (default: 1000)')
    
    args = parser.parse_args()

    # ë””ë°”ì´ìŠ¤ ì„¤ì •
    device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')
    print(f"ğŸ® Using device: {device}")

    # í™˜ê²½ ì„¤ì •
    print("ğŸ Setting up CarRacing environment...")
    
    # 1) ì´ì‚° ì•¡ì…˜ ë˜í¼ ì ìš©
    discrete_env = CarRacingDiscrete(resize=(84, 84))
    
    # 2) ë¹„ë””ì˜¤ ë…¹í™” ë˜í¼ ì ìš©
    model_name = os.path.splitext(os.path.basename(args.weights))[0]
    video_folder = f"student_videos_{model_name}"
    env = RecordVideo(
        discrete_env,
        video_folder=video_folder,
        name_prefix="student_play",
        episode_trigger=lambda episode_id: True  # ëª¨ë“  ì—í”¼ì†Œë“œ ë…¹í™”
    )

    # ëª¨ë¸ ë¡œë“œ
    print("ğŸ§  Loading student model...")
    student_net = DQN(84, 84, 7).to(device)
    
    try:
        # PyTorch 2.6+ í˜¸í™˜ì„±ì„ ìœ„í•´ weights_only=False ì„¤ì •
        try:
            checkpoint = torch.load(args.weights, map_location=device, weights_only=False)
        except Exception as first_error:
            print(f"âš ï¸  First attempt failed: {first_error}")
            print("ğŸ”„ Trying alternative loading method...")
            
            # numpy ê´€ë ¨ ì „ì—­ í•¨ìˆ˜ í—ˆìš©
            import torch.serialization
            with torch.serialization.safe_globals([]):
                checkpoint = torch.load(args.weights, map_location=device, weights_only=False)
        
        # ì²´í¬í¬ì¸íŠ¸ í˜•íƒœì— ë”°ë¼ ë‹¤ë¥´ê²Œ ì²˜ë¦¬
        if isinstance(checkpoint, dict):
            if 'student_net' in checkpoint:
                # final save í˜•íƒœ
                student_net.load_state_dict(checkpoint['student_net'])
                print("âœ… Loaded from final checkpoint format")
            elif 'student_state_dict' in checkpoint:
                # intermediate checkpoint í˜•íƒœ
                student_net.load_state_dict(checkpoint['student_state_dict'])
                print("âœ… Loaded from intermediate checkpoint format")
            elif all(key.startswith(('conv', 'fc', 'head')) for key in checkpoint.keys()):
                # ë‹¨ìˆœ state_dict í˜•íƒœ (ë ˆì´ì–´ ì´ë¦„ìœ¼ë¡œ íŒë‹¨)
                student_net.load_state_dict(checkpoint)
                print("âœ… Loaded from simple state_dict format")
            else:
                # ì¼ë°˜ì ì¸ ë”•ì…”ë„ˆë¦¬ì—ì„œ state_dict ì°¾ê¸°
                for key in checkpoint.keys():
                    if 'state_dict' in key or key == 'model':
                        student_net.load_state_dict(checkpoint[key])
                        print(f"âœ… Loaded from checkpoint key: {key}")
                        break
                else:
                    # ë§ˆì§€ë§‰ ì‹œë„: ì „ì²´ ë”•ì…”ë„ˆë¦¬ë¥¼ state_dictë¡œ ì‚¬ìš©
                    student_net.load_state_dict(checkpoint)
                    print("âœ… Loaded using entire checkpoint as state_dict")
        else:
            # ì²´í¬í¬ì¸íŠ¸ê°€ ë”•ì…”ë„ˆë¦¬ê°€ ì•„ë‹Œ ê²½ìš°
            student_net.load_state_dict(checkpoint)
            print("âœ… Loaded from direct state_dict")
            
    except Exception as e:
        print(f"âŒ Error loading model: {e}")
        print("\nğŸ” Debugging info:")
        print(f"   File: {args.weights}")
        print(f"   File exists: {os.path.exists(args.weights)}")
        if os.path.exists(args.weights):
            print(f"   File size: {os.path.getsize(args.weights)} bytes")
        
        # íŒŒì¼ ë‚´ìš© í™•ì¸ ì‹œë„
        try:
            checkpoint = torch.load(args.weights, map_location='cpu', weights_only=False)
            if isinstance(checkpoint, dict):
                print(f"   Checkpoint keys: {list(checkpoint.keys())}")
            print("   Checkpoint type:", type(checkpoint))
        except Exception as debug_error:
            print(f"   Debug load failed: {debug_error}")
        
        exit(1)
    
    student_net.eval()
    print("âœ… Student model loaded and set to evaluation mode")

    # í”„ë ˆì„ ìŠ¤íƒ ì¤€ë¹„
    frame_stack = FrameStack(4)

    # ì—í”¼ì†Œë“œ ì‹¤í–‰
    print(f"ğŸ¬ Starting to record {args.episodes} episodes...")
    total_rewards = []
    
    for episode in range(1, args.episodes + 1):
        print(f"\nğŸ“¹ Recording Episode {episode}/{args.episodes}")
        
        # í™˜ê²½ ë¦¬ì…‹ (ì¬í˜„ ê°€ëŠ¥í•œ ê²°ê³¼ë¥¼ ìœ„í•´ ì‹œë“œ ì„¤ì •)
        obs, _ = env.reset(seed=args.seed + episode)
        state = frame_stack.reset(obs)
        
        total_reward = 0.0
        steps = 0
        done = False

        while not done and steps < args.max_steps:
            # í˜„ì¬ ìƒíƒœë¥¼ í…ì„œë¡œ ë³€í™˜
            state_tensor = torch.from_numpy(state).unsqueeze(0).to(device).float()
            
            # ëª¨ë¸ì„ ì‚¬ìš©í•´ ì•¡ì…˜ ì„ íƒ (epsilon-greedy ì—†ì´ ìˆœìˆ˜ ì˜ˆì¸¡)
            with torch.no_grad():
                q_values = student_net(state_tensor)
                action = q_values.argmax(dim=1).item()
            
            # ì•¡ì…˜ ì‹¤í–‰
            obs, reward, terminated, truncated, info = env.step(action)
            total_reward += reward
            steps += 1
            
            # ì¢…ë£Œ ì¡°ê±´ ì²´í¬
            done = terminated or truncated
            
            # ë‹¤ìŒ ìƒíƒœ ì¤€ë¹„
            if not done:
                state = frame_stack.step(obs)

        total_rewards.append(total_reward)
        print(f"âœ… Episode {episode} completed: {steps} steps, reward: {total_reward:.2f}")

    # ê²°ê³¼ ìš”ì•½
    env.close()
    
    print(f"\nğŸ‰ Recording completed!")
    print(f"ğŸ“ Videos saved to: ./{video_folder}/")
    print(f"ğŸ“Š Episode Results:")
    for i, reward in enumerate(total_rewards, 1):
        print(f"   Episode {i}: {reward:.2f}")
    print(f"ğŸ“ˆ Average Reward: {np.mean(total_rewards):.2f} Â± {np.std(total_rewards):.2f}")
    
    # í•˜ì´í¼íŒŒë¼ë¯¸í„° ì •ë³´ ì¶œë ¥ (ê°€ëŠ¥í•œ ê²½ìš°)
    try:
        checkpoint = torch.load(args.weights, map_location='cpu', weights_only=False)
        if isinstance(checkpoint, dict) and 'hyperparameters' in checkpoint:
            print(f"\nğŸ”§ Model Hyperparameters:")
            for key, value in checkpoint['hyperparameters'].items():
                print(f"   {key}: {value}")
    except:
        pass